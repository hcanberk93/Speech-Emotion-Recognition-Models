# Speech-Emotion-Recognition-Models
In this project, several Speech Emotion Recognition models had attempted to be built with Tensorflow v3.8 and Keras v2.4.3.

Prerequisites:

ER-Huang: RAVDESS and TESS Datasets

ER-Gumelar: RAVDESS

ER-Vryzas: AESDD

ER-Mustaqeem:RAVDESS and IEMOCAP


The success ratios are as below:
Huang: %83

Gumelar: %40 (Failure)

Vryzas: %65

Mustaqeem: %69

References:

[1] A. Huang, P. Bao, ” Human Vocal Sentiment Analysis,”, arXiv:1905.08632 [cs], May
2019

[2] A. B. Gumelar vd., “Human Voice Emotion Identification Using Prosodic and Spectral
Feature Extraction Based on Deep Neural Networks”, presented at the 2019 IEEE 7th
International Conference on Serious Games and Applications for Health (SeGAH), Aug.
2019, doi: 10.1109/segah.2019.8882461.

[3] N. Vryzas, L. Vrysis, M. Matsiola, R. Kotsakis, C. Dimoulas, ve G. Kalliris, “Continuous
Speech Emotion Recognition with Convolutional Neural Networks”, J. Audio Eng. Soc., c.
68, sy 1/2, ss. 14-24, Feb. 2020, doi: 10.17743/jaes.2019.0043.

[4] Mustaqeem ve S. Kwon, “A CNN-Assisted Enhanced Audio Signal Processing for
Speech Emotion Recognition”, Sensors, c. 20, sy 1, s. 183, Dec. 2019, doi:
10.3390/s20010183.
